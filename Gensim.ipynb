{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim is a Natural Language Processing package that does ‘Topic Modeling for Humans’. But it is practically much more than that. It is a leading and a state-of-the-art package for the purpose of  processing texts, working with word vector models (such as Word2Vec, FastText etc) and for building topic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from gensim import corpora,logger,models,parsing \n",
    "\n",
    "\n",
    "## Load Text Data \n",
    "doc1_path = os.getcwd()+\"/GeneralText.txt\"\n",
    "doc2_path = os.getcwd()+\"/GeneralText2.txt\"\n",
    "doc_1 = open(doc1_path,\"r\")\n",
    "doc_2 = open(doc2_path,\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial Preprocessing for the documents\n",
    "## conversion to lower case \n",
    "## removal of special chars\n",
    "## removal of unwanted identifiers\n",
    "\n",
    "#### On Hold so far #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = [i for i in doc_1.readline().split(\".\")]\n",
    "doc2 = [i for i in doc_2.readline().split(\".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"History (from Greek ἱστορία, historia, meaning 'inquiry; knowledge acquired by investigation')[2] is the past as it is described in written documents, and the study thereof\",\n",
       " '[3][4] Events occurring before written records are considered prehistory',\n",
       " ' \"History\" is an umbrella term that relates to past events as well as the memory, discovery, collection, organization, presentation, and interpretation of information about these events',\n",
       " ' Scholars who write about history are called historians',\n",
       " '\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Coming of age ceremonies have been celebrated in Japan since at least 714 CE, when a young prince donned new robes and a hairstyle to mark his passage into adulthood',\n",
       " '  The holiday was first established in 1948, to be held every year on January 15',\n",
       " '  In 2000, as a result of the Happy Monday System, Coming of Age Day was changed to the second Monday in January',\n",
       " ' \\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Converting docs to list of sentences\n",
    "## list of list of words in every lineof the document\n",
    "\n",
    "docList1 = [[word for word in line.split()] for line in doc1]\n",
    "docList2 = [[word for word in line.split()] for line in doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Coming',\n",
       "  'of',\n",
       "  'age',\n",
       "  'ceremonies',\n",
       "  'have',\n",
       "  'been',\n",
       "  'celebrated',\n",
       "  'in',\n",
       "  'Japan',\n",
       "  'since',\n",
       "  'at',\n",
       "  'least',\n",
       "  '714',\n",
       "  'CE,',\n",
       "  'when',\n",
       "  'a',\n",
       "  'young',\n",
       "  'prince',\n",
       "  'donned',\n",
       "  'new',\n",
       "  'robes',\n",
       "  'and',\n",
       "  'a',\n",
       "  'hairstyle',\n",
       "  'to',\n",
       "  'mark',\n",
       "  'his',\n",
       "  'passage',\n",
       "  'into',\n",
       "  'adulthood'],\n",
       " ['The',\n",
       "  'holiday',\n",
       "  'was',\n",
       "  'first',\n",
       "  'established',\n",
       "  'in',\n",
       "  '1948,',\n",
       "  'to',\n",
       "  'be',\n",
       "  'held',\n",
       "  'every',\n",
       "  'year',\n",
       "  'on',\n",
       "  'January',\n",
       "  '15'],\n",
       " ['In',\n",
       "  '2000,',\n",
       "  'as',\n",
       "  'a',\n",
       "  'result',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Happy',\n",
       "  'Monday',\n",
       "  'System,',\n",
       "  'Coming',\n",
       "  'of',\n",
       "  'Age',\n",
       "  'Day',\n",
       "  'was',\n",
       "  'changed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'second',\n",
       "  'Monday',\n",
       "  'in',\n",
       "  'January'],\n",
       " []]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docList2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign every token in the text an unique id\n",
    "## Gensim is very smart in that task, if the text is huge and unable to fit ion memory\n",
    "## you can still work with that by dynamic id assignment\n",
    "##### Let's convert the entire text to dictionary which contains token as key and unique id  as value.\n",
    "\n",
    "# 1.Convert the text to list which is tokenized \n",
    "# 2. Pass the list to gensim corpora.Dictionary() to create the dictionary of tokens with id.\n",
    "\n",
    "## Some NLP Jargon::\n",
    "## Token =  word\n",
    "## A ‘document’ can typically refer to a ‘sentence’ or ‘paragraph’.\n",
    "## A ‘corpus’ is typically a ‘collection of documents as a bag of words’.\n",
    "\n",
    "# bow = []\n",
    "# with open(file_Path) as fp:\n",
    "#     line = fp.readline()\n",
    "#     while line:\n",
    "#         line = fp.readline()\n",
    "#         text_list = list(line.split(\" \"))\n",
    "#         bow.append(text_list)    \n",
    "\n",
    "        \n",
    "dictionary = corpora.Dictionary(docList1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(56 unique tokens: [\"'inquiry;\", '(from', 'Greek', 'History', 'acquired']...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{\"'inquiry;\": 0,\n",
       " '(from': 1,\n",
       " 'Greek': 2,\n",
       " 'History': 3,\n",
       " 'acquired': 4,\n",
       " 'and': 5,\n",
       " 'as': 6,\n",
       " 'by': 7,\n",
       " 'described': 8,\n",
       " 'documents,': 9,\n",
       " 'historia,': 10,\n",
       " 'in': 11,\n",
       " \"investigation')[2]\": 12,\n",
       " 'is': 13,\n",
       " 'it': 14,\n",
       " 'knowledge': 15,\n",
       " 'meaning': 16,\n",
       " 'past': 17,\n",
       " 'study': 18,\n",
       " 'the': 19,\n",
       " 'thereof': 20,\n",
       " 'written': 21,\n",
       " 'ἱστορία,': 22,\n",
       " 'Events': 23,\n",
       " '[3][4]': 24,\n",
       " 'are': 25,\n",
       " 'before': 26,\n",
       " 'considered': 27,\n",
       " 'occurring': 28,\n",
       " 'prehistory': 29,\n",
       " 'records': 30,\n",
       " '\"History\"': 31,\n",
       " 'about': 32,\n",
       " 'an': 33,\n",
       " 'collection,': 34,\n",
       " 'discovery,': 35,\n",
       " 'events': 36,\n",
       " 'information': 37,\n",
       " 'interpretation': 38,\n",
       " 'memory,': 39,\n",
       " 'of': 40,\n",
       " 'organization,': 41,\n",
       " 'presentation,': 42,\n",
       " 'relates': 43,\n",
       " 'term': 44,\n",
       " 'that': 45,\n",
       " 'these': 46,\n",
       " 'to': 47,\n",
       " 'umbrella': 48,\n",
       " 'well': 49,\n",
       " 'Scholars': 50,\n",
       " 'called': 51,\n",
       " 'historians': 52,\n",
       " 'history': 53,\n",
       " 'who': 54,\n",
       " 'write': 55}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dictionary)\n",
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docList2\n",
    "dictionary.add_documents(docList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'inquiry;\": 0,\n",
       " '(from': 1,\n",
       " 'Greek': 2,\n",
       " 'History': 3,\n",
       " 'acquired': 4,\n",
       " 'and': 5,\n",
       " 'as': 6,\n",
       " 'by': 7,\n",
       " 'described': 8,\n",
       " 'documents,': 9,\n",
       " 'historia,': 10,\n",
       " 'in': 11,\n",
       " \"investigation')[2]\": 12,\n",
       " 'is': 13,\n",
       " 'it': 14,\n",
       " 'knowledge': 15,\n",
       " 'meaning': 16,\n",
       " 'past': 17,\n",
       " 'study': 18,\n",
       " 'the': 19,\n",
       " 'thereof': 20,\n",
       " 'written': 21,\n",
       " 'ἱστορία,': 22,\n",
       " 'Events': 23,\n",
       " '[3][4]': 24,\n",
       " 'are': 25,\n",
       " 'before': 26,\n",
       " 'considered': 27,\n",
       " 'occurring': 28,\n",
       " 'prehistory': 29,\n",
       " 'records': 30,\n",
       " '\"History\"': 31,\n",
       " 'about': 32,\n",
       " 'an': 33,\n",
       " 'collection,': 34,\n",
       " 'discovery,': 35,\n",
       " 'events': 36,\n",
       " 'information': 37,\n",
       " 'interpretation': 38,\n",
       " 'memory,': 39,\n",
       " 'of': 40,\n",
       " 'organization,': 41,\n",
       " 'presentation,': 42,\n",
       " 'relates': 43,\n",
       " 'term': 44,\n",
       " 'that': 45,\n",
       " 'these': 46,\n",
       " 'to': 47,\n",
       " 'umbrella': 48,\n",
       " 'well': 49,\n",
       " 'Scholars': 50,\n",
       " 'called': 51,\n",
       " 'historians': 52,\n",
       " 'history': 53,\n",
       " 'who': 54,\n",
       " 'write': 55,\n",
       " '714': 56,\n",
       " 'CE,': 57,\n",
       " 'Coming': 58,\n",
       " 'Japan': 59,\n",
       " 'a': 60,\n",
       " 'adulthood': 61,\n",
       " 'age': 62,\n",
       " 'at': 63,\n",
       " 'been': 64,\n",
       " 'celebrated': 65,\n",
       " 'ceremonies': 66,\n",
       " 'donned': 67,\n",
       " 'hairstyle': 68,\n",
       " 'have': 69,\n",
       " 'his': 70,\n",
       " 'into': 71,\n",
       " 'least': 72,\n",
       " 'mark': 73,\n",
       " 'new': 74,\n",
       " 'passage': 75,\n",
       " 'prince': 76,\n",
       " 'robes': 77,\n",
       " 'since': 78,\n",
       " 'when': 79,\n",
       " 'young': 80,\n",
       " '15': 81,\n",
       " '1948,': 82,\n",
       " 'January': 83,\n",
       " 'The': 84,\n",
       " 'be': 85,\n",
       " 'established': 86,\n",
       " 'every': 87,\n",
       " 'first': 88,\n",
       " 'held': 89,\n",
       " 'holiday': 90,\n",
       " 'on': 91,\n",
       " 'was': 92,\n",
       " 'year': 93,\n",
       " '2000,': 94,\n",
       " 'Age': 95,\n",
       " 'Day': 96,\n",
       " 'Happy': 97,\n",
       " 'In': 98,\n",
       " 'Monday': 99,\n",
       " 'System,': 100,\n",
       " 'changed': 101,\n",
       " 'result': 102,\n",
       " 'second': 103}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above created dictionary , we will create the Bag of Words corpus, which Gensim will use for token replacement in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roller(document):\n",
    "    finalDoc = list()\n",
    "    for i in document:\n",
    "        for j in i:\n",
    "            finalDoc.append(j)\n",
    "    return finalDoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_1 = roller(docList1)\n",
    "documrnt_2 = roller(docList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating BOW from dictionary\n",
    "Bow_1 = dictionary.doc2bow(document_1,allow_update=True)\n",
    "Bow_2 = dictionary.doc2bow(document_1,allow_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to persist dictionary and BoW to Disk\n",
    "dictionary.save(os.getcwd()+\"Gensim_dict.dict\")\n",
    "# corpora.MmCorpus.serialize(\"Bow_1.mm\", Bow_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
